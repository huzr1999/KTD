{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']\n",
    "plt.rcParams['text.usetex'] = False\n",
    "# plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "from lib.utils import get_results, calc_grad_l2_norm, load_dataset\n",
    "name_map = {\"gpt2\": \"GPT-2\", \"pythia\": \"Pythia\", \"gpt-neo\": \"GPT-Neo\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.knockoff import evalute_knockoff\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "num_knockoffs = 10\n",
    "finetuned = True\n",
    "\n",
    "# dataset_name = \"xsum\"\n",
    "saved_dir = os.path.abspath(\"./saved_tensors/grad_norms\")\n",
    "figure_dir = os.path.abspath(\"./figures\")\n",
    "\n",
    "\n",
    "\n",
    "for i, dataset_name in enumerate([\"wiki\", \"xsum\", \"bbc\"]):\n",
    "    dataset, input_column_name = load_dataset(dataset_name, 10)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 6), sharex=True)\n",
    "\n",
    "    for model_name in [\"gpt2\", \"pythia\", \"gpt-neo\"]:\n",
    "        saved_file_name = f\"{model_name}-{dataset_name}-{num_knockoffs}-{finetuned}.pt\"\n",
    "        ft_origin_grad, ft_nkf_grad = torch.load(os.path.join(saved_dir, saved_file_name), map_location=\"cpu\")\n",
    "\n",
    "        ft_origin_l2_norm = calc_grad_l2_norm(ft_origin_grad)\n",
    "        ft_nkf_l2_norm = calc_grad_l2_norm(ft_nkf_grad)\n",
    "\n",
    "        results = get_results(ft_origin_l2_norm, ft_nkf_l2_norm)\n",
    "\n",
    "        q_list = np.arange(1, 20) * 0.05\n",
    "        m_list = [evalute_knockoff(-results, dataset[\"label\"], q) for q in q_list]\n",
    "\n",
    "        power_list = [m[2] for m in m_list]\n",
    "        fdr_list = [1 - m[1] for m in m_list]\n",
    "\n",
    "        ax1.plot(q_list, power_list, \"o-\", label=f\"{name_map[model_name]}\", markersize=4)\n",
    "        # if i == 0:\n",
    "        ax1.set_ylabel(\"Power\", fontsize=16)\n",
    "        ax1.tick_params(axis='x', which='both', labelbottom=True)\n",
    "        # ax1.set_xticks(q_list)\n",
    "        ax2.plot(q_list, fdr_list, \"o-\", label=f\"{name_map[model_name]}\", markersize=4)\n",
    "        # if i == 0:\n",
    "        ax2.set_ylabel(\"FDR\", fontsize=16)\n",
    "        ax2.set_xticks(np.arange(1, 10) * 0.1)\n",
    "        # plot_two_hist(-results, dataset)\n",
    "        ax1.tick_params(axis='x', labelsize=14)\n",
    "        ax1.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "        ax2.tick_params(axis='x', labelsize=14)\n",
    "        ax2.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "    ax2.plot(q_list, q_list, \"o-\", label=\"Bound\", markersize=4)\n",
    "    ax2.legend(fontsize=16)\n",
    "    ax2.set_xlabel(\"q\", fontsize=16)\n",
    "    fig.tight_layout()\n",
    "    # fig.savefig(os.path.join(figure_dir, f\"{dataset_name}_fdr_control.pdf\"), bbox_inches='tight', pad_inches=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds = load_from_disk(\"./datasets/xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['document', 'summary', 'id', 'label'],\n",
       "    num_rows: 11332\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
